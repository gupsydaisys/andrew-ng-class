{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the things\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from scipy.io import loadmat\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data + general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = scipy.io.loadmat('ex3data1.mat')\n",
    "\n",
    "# m by n ie 5000 samples by 400 features NUMPY ARRAY\n",
    "X = f['X']\n",
    "\n",
    "# m dim NUMPY ARRAY\n",
    "y = f['y']\n",
    "\n",
    "    \n",
    "## Grab m (# number of samples) and n (# of features)\n",
    "m, n = X.shape\n",
    "    \n",
    "# X_with_one_column.shape (5000, 401)\n",
    "first_column = np.matrix('1 '*m).T\n",
    "X_with_one_column = np.append(first_column, X, 1)\n",
    "\n",
    "# X.shape, y.shape\n",
    "learning_rate = 1\n",
    "\n",
    "# theta is n+1 dimensional (+1 for element at index 0 which has no X)\n",
    "theta = np.matrix('.01 '* (n+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out functions previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.7918144159156"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost2(theta, X, y, learning_rate):\n",
    "    ######## SETUP #######\n",
    "    ## Add column of 1s to X ... goes from being m by n to m by n+1\n",
    "    ## (5000, 400) ......>>>>>> (5000, 401)\n",
    "    first_column = np.matrix('1 '*y.size).T\n",
    "    X_with_one_column = np.append(first_column, X, 1)\n",
    "    \n",
    "    ## Grab m (# number of samples) and n (# of features)\n",
    "    m, n = X.shape\n",
    "    \n",
    "    ## Remove first theta when using regularization\n",
    "    theta_without_first_term = np.delete(theta, 0)\n",
    "    #####################\n",
    "    \n",
    "    # Should now be m-dimensional (1, 5000)\n",
    "    X_theta = theta*X_with_one_column.T \n",
    "    \n",
    "    # Should now be m-dimensional (1, 5000)\n",
    "    h = sigmoid(X_theta) \n",
    "    \n",
    "    # Scalar\n",
    "    y_is_one = np.log(h)*(-y)\n",
    "    y_is_zero =np.log(1-h)*(1 - y)\n",
    "    cost = np.asscalar((y_is_one - y_is_zero) / m)\n",
    "    regularization_term = (learning_rate * np.sum(np.power(theta_without_first_term, 2)))/(2*m)\n",
    "    return cost + regularization_term\n",
    "\n",
    "cost2(theta, X, y, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.7918144159156"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost(theta, X, y, learning_rate):\n",
    "    y = y.T\n",
    "    m = y.size\n",
    "    theta_without_first_term = np.delete(theta, 0)\n",
    "    \n",
    "    # Should now be m-dimensional (1, 5000)\n",
    "    X_theta = theta*X.T \n",
    "    \n",
    "    # Should now be m-dimensional (1, 5000)\n",
    "    h = sigmoid(X_theta) \n",
    "    \n",
    "    # Scalar\n",
    "    y_is_one = np.log(h)*(-y)\n",
    "    y_is_zero =np.log(1-h)*(1 - y)\n",
    "    cost = np.asscalar((y_is_one - y_is_zero) / m)\n",
    "    regularization_term = (learning_rate * np.sum(np.power(theta_without_first_term, 2)))/(2*m)\n",
    "    return cost + regularization_term\n",
    "\n",
    "cost(theta, X_with_one_column, y.T, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient2(theta, X, y, learning_rate):\n",
    "    ################ SETUP ###############\n",
    "    ## Add column of 1s to X ... goes from being m by n to m by n+1\n",
    "    ## (5000, 400) ......>>>>>> (5000, 401)\n",
    "    first_column = np.matrix('1 '*y.size).T\n",
    "    X_with_one_column = np.append(first_column, X, 1)\n",
    "    ## Grab m (# number of samples) and n (# of features)\n",
    "    m, n = X.shape\n",
    "    #####################################\n",
    "    h = sigmoid(theta*X_with_one_column.T)\n",
    "    diff = h - y.T\n",
    "    first_term = (diff * X_with_one_column) / m\n",
    "    reqularization_term = theta*(learning_rate/m)\n",
    "    reqularization_term[0,0] = theta[0, 0]\n",
    "    return reqularization_term + first_term\n",
    "\n",
    "gradient2(theta, X, y, learning_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.87015768e+00,  0.00000000e+00,  0.00000000e+00, -6.59186418e-08,\n",
       "        3.03375475e-06,  1.85651595e-05, -6.90794664e-04, -8.80456507e-04,\n",
       "       -3.67077352e-04, -1.10827298e-04, -1.32149427e-04, -3.93899051e-05,\n",
       "        2.95906684e-05,  7.26919096e-05,  1.60579127e-04,  1.79557439e-04,\n",
       "        1.04246826e-04,  3.22844010e-05,  2.27185250e-07, -3.43517453e-07,\n",
       "        0.00000000e+00, -2.63613707e-07,  2.62168396e-06,  1.23763377e-06,\n",
       "        4.88432398e-05,  8.59251343e-05, -1.11883866e-03, -3.98041022e-03,\n",
       "       -5.55860517e-03, -4.30392409e-03, -1.21016777e-03,  1.04056335e-03,\n",
       "        1.63769540e-03,  1.77891638e-03,  1.34886454e-03,  9.74691973e-04,\n",
       "        6.15803555e-04,  2.79766072e-04,  1.61375792e-04,  4.44252054e-05,\n",
       "        1.62656919e-05,  2.26168352e-06, -2.54673503e-05,  5.73484834e-05,\n",
       "       -2.43904013e-04, -2.04429304e-03, -1.07639157e-02, -2.35359268e-02,\n",
       "       -3.05914084e-02, -2.30009537e-02, -1.02480591e-02, -4.43011224e-03,\n",
       "       -2.04719503e-03, -6.73645426e-03, -1.85372969e-02, -2.31841802e-02,\n",
       "       -1.24050676e-02, -3.37389625e-03, -7.55445155e-04,  1.16309629e-04,\n",
       "       -9.42064644e-05,  9.53262370e-06, -4.86311752e-05, -3.12938291e-04,\n",
       "       -4.08195977e-03, -1.46619167e-02, -5.31073834e-02, -9.92681782e-02,\n",
       "       -1.27704434e-01, -1.32387584e-01, -1.41624766e-01, -1.78851656e-01,\n",
       "       -2.18275533e-01, -2.58769616e-01, -2.78343737e-01, -2.51289322e-01,\n",
       "       -1.61440098e-01, -6.32873008e-02, -1.48837560e-02, -4.68924904e-03,\n",
       "       -1.14736961e-03,  1.15474336e-05,  9.48869898e-05, -1.50371234e-03,\n",
       "       -1.29244499e-02, -5.02407982e-02, -1.43828431e-01, -2.76757037e-01,\n",
       "       -3.79067094e-01, -4.60357777e-01, -5.67168338e-01, -6.79710760e-01,\n",
       "       -7.37624972e-01, -7.48601978e-01, -7.70501646e-01, -7.54890615e-01,\n",
       "       -5.71338398e-01, -2.74051610e-01, -7.45412804e-02, -2.70849261e-02,\n",
       "       -6.25415032e-03, -1.62927941e-04, -5.47204629e-04, -3.74745050e-03,\n",
       "       -3.74138179e-02, -1.42630449e-01, -3.90875058e-01, -7.17532326e-01,\n",
       "       -9.64959473e-01, -1.16458206e+00, -1.34523662e+00, -1.39155122e+00,\n",
       "       -1.29899872e+00, -1.20308073e+00, -1.21057228e+00, -1.28526050e+00,\n",
       "       -1.16945599e+00, -7.16131168e-01, -2.60107474e-01, -9.61759990e-02,\n",
       "       -1.74455852e-02, -3.41127401e-04, -2.49842722e-03, -1.23007944e-02,\n",
       "       -9.36354895e-02, -3.46663134e-01, -8.64246492e-01, -1.40424633e+00,\n",
       "       -1.79242574e+00, -1.98937221e+00, -2.04224817e+00, -1.90027398e+00,\n",
       "       -1.66069791e+00, -1.43921570e+00, -1.38240249e+00, -1.54789853e+00,\n",
       "       -1.65073757e+00, -1.28394240e+00, -5.56893681e-01, -1.84153702e-01,\n",
       "       -2.73029829e-02, -2.55992114e-05, -4.48956240e-03, -3.15870405e-02,\n",
       "       -2.24042300e-01, -7.34436932e-01, -1.54777091e+00, -2.24554417e+00,\n",
       "       -2.51448937e+00, -2.38201977e+00, -2.17995177e+00, -1.96667916e+00,\n",
       "       -1.75740210e+00, -1.48760031e+00, -1.37943332e+00, -1.63205020e+00,\n",
       "       -2.03935269e+00, -1.88155942e+00, -8.98290331e-01, -2.53953542e-01,\n",
       "       -3.51543081e-02,  6.39836554e-05, -4.41905091e-03, -6.28236030e-02,\n",
       "       -4.43671775e-01, -1.23859510e+00, -2.23438935e+00, -2.75714061e+00,\n",
       "       -2.48997998e+00, -2.01528629e+00, -1.83610815e+00, -1.85860325e+00,\n",
       "       -1.78813134e+00, -1.44308539e+00, -1.30100841e+00, -1.73265032e+00,\n",
       "       -2.36857489e+00, -2.28020536e+00, -1.09274588e+00, -2.59883626e-01,\n",
       "       -3.84642067e-02,  6.53429003e-04, -7.58514608e-03, -1.16700041e-01,\n",
       "       -7.27873529e-01, -1.77833713e+00, -2.72159591e+00, -2.68153671e+00,\n",
       "       -1.89229332e+00, -1.40947299e+00, -1.53118953e+00, -1.91290854e+00,\n",
       "       -1.88341374e+00, -1.51116644e+00, -1.50460829e+00, -2.06850676e+00,\n",
       "       -2.61623755e+00, -2.32244155e+00, -1.08554566e+00, -2.50529461e-01,\n",
       "       -4.07776709e-02,  1.91812613e-03, -1.86613755e-02, -1.97098995e-01,\n",
       "       -1.02781739e+00, -2.24313956e+00, -2.86427067e+00, -2.26064435e+00,\n",
       "       -1.31517251e+00, -1.09287320e+00, -1.60009185e+00, -2.17473999e+00,\n",
       "       -2.17103470e+00, -1.95533962e+00, -2.01384387e+00, -2.41638308e+00,\n",
       "       -2.60700584e+00, -2.01384989e+00, -9.07250146e-01, -2.32221240e-01,\n",
       "       -3.81584560e-02,  3.08269074e-03, -3.40292428e-02, -2.66083624e-01,\n",
       "       -1.17800881e+00, -2.35460602e+00, -2.76802330e+00, -2.05424066e+00,\n",
       "       -1.34334998e+00, -1.43363456e+00, -2.10025421e+00, -2.55981040e+00,\n",
       "       -2.47700272e+00, -2.26742398e+00, -2.27041517e+00, -2.45629992e+00,\n",
       "       -2.27787999e+00, -1.52434016e+00, -6.58499095e-01, -1.87073081e-01,\n",
       "       -2.79463539e-02,  3.99671607e-03, -4.11021779e-02, -2.66860393e-01,\n",
       "       -1.09608074e+00, -2.11547470e+00, -2.58341954e+00, -2.20953678e+00,\n",
       "       -1.84963893e+00, -2.03644503e+00, -2.42487756e+00, -2.52027715e+00,\n",
       "       -2.34041476e+00, -2.16736527e+00, -2.18969228e+00, -2.14910223e+00,\n",
       "       -1.67528013e+00, -9.70689063e-01, -4.00858813e-01, -1.25113821e-01,\n",
       "       -1.67804242e-02,  3.06190082e-03, -2.96520481e-02, -1.87100744e-01,\n",
       "       -8.05801517e-01, -1.64946124e+00, -2.24451516e+00, -2.29469046e+00,\n",
       "       -2.16557566e+00, -2.15533803e+00, -2.07465541e+00, -1.90149134e+00,\n",
       "       -1.80690744e+00, -1.79332590e+00, -1.76429264e+00, -1.51567594e+00,\n",
       "       -1.01173203e+00, -5.25220947e-01, -2.10487103e-01, -6.26864365e-02,\n",
       "       -6.45957520e-03,  1.13350247e-03, -1.34908083e-02, -9.41820482e-02,\n",
       "       -4.89565214e-01, -1.10317437e+00, -1.70692709e+00, -1.97091680e+00,\n",
       "       -1.93439760e+00, -1.73244200e+00, -1.49343517e+00, -1.37299500e+00,\n",
       "       -1.36824592e+00, -1.34076477e+00, -1.16622916e+00, -8.72567900e-01,\n",
       "       -5.07154330e-01, -2.42977110e-01, -1.09271093e-01, -3.66024356e-02,\n",
       "       -2.95051517e-03,  1.37503162e-04, -3.17344592e-03, -3.02440572e-02,\n",
       "       -2.34366094e-01, -6.05465335e-01, -1.01750231e+00, -1.25789440e+00,\n",
       "       -1.22502254e+00, -1.06849284e+00, -9.78883181e-01, -9.47216739e-01,\n",
       "       -9.04316066e-01, -7.93220459e-01, -6.04394913e-01, -3.84752244e-01,\n",
       "       -1.87472804e-01, -8.90731250e-02, -4.73254235e-02, -1.88619987e-02,\n",
       "       -2.62386543e-03, -7.52699318e-06,  3.83378341e-04, -8.53907736e-03,\n",
       "       -1.05647467e-01, -3.00842005e-01, -5.01897905e-01, -5.88236087e-01,\n",
       "       -5.59005064e-01, -5.23885527e-01, -5.35465900e-01, -5.29326770e-01,\n",
       "       -4.75013945e-01, -3.66977161e-01, -2.40543966e-01, -1.33599813e-01,\n",
       "       -6.04987232e-02, -2.72511760e-02, -1.38905170e-02, -5.45265023e-03,\n",
       "       -9.44144973e-04,  1.15011909e-05,  3.03210828e-04, -8.03020304e-04,\n",
       "       -3.17762307e-02, -1.10162473e-01, -1.77818418e-01, -1.66340210e-01,\n",
       "       -1.14696864e-01, -1.17906316e-01, -1.45593379e-01, -1.50229417e-01,\n",
       "       -1.31524068e-01, -9.65708672e-02, -5.20141034e-02, -2.67308184e-02,\n",
       "       -1.36675176e-02, -4.08459925e-03, -9.32732323e-04, -5.09866609e-04,\n",
       "        6.37465521e-05, -4.60109941e-07,  4.67634765e-07,  4.48008253e-04,\n",
       "       -1.93177537e-03, -1.93633918e-02, -3.84757782e-02, -2.32393500e-02,\n",
       "       -2.38878249e-03,  1.51768509e-03,  7.04206495e-04, -9.21328821e-04,\n",
       "       -1.11082607e-03, -2.35158204e-03, -6.92442990e-04, -8.15180465e-04,\n",
       "       -1.83632264e-03, -4.77268973e-04,  2.47707761e-04,  7.17717630e-05,\n",
       "        6.63594761e-06,  0.00000000e+00, -1.20751329e-06,  2.11175865e-05,\n",
       "        5.37705331e-05, -1.94386649e-03, -2.91100611e-03, -5.68362171e-04,\n",
       "        1.41322340e-04, -7.53028062e-04,  1.62272601e-04,  5.76776342e-04,\n",
       "        1.75611179e-04, -1.21549849e-04,  1.27191968e-04, -1.95801364e-04,\n",
       "       -4.55947766e-04, -1.16217362e-04,  7.83457345e-06,  5.43201186e-07,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient(theta, X, y, learning_rate):\n",
    "    y = y.T\n",
    "    #m = y.size\n",
    "    #h = sigmoid(theta*X.T)\n",
    "    #diff = h - y.T\n",
    "    #first_term = (diff * X) / m\n",
    "    #reqularization_term = theta*(learning_rate/m)\n",
    "    #reqularization_term[0,0] = theta[0, 0]\n",
    "    #return reqularization_term + first_term\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    grad = ((X.T * error) / len(X)).T + ((learning_rate / len(X)) * theta)\n",
    "    \n",
    "    # intercept gradient is not regularized\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
    "    \n",
    "    return np.array(grad).ravel()\n",
    "\n",
    "gradient(theta, X_with_one_column, y.T, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_vs_all(X, y, num_labels, learning_rate):\n",
    "fmins = []\n",
    "for i in range(1, 11):\n",
    "    theta = np.zeros(n + 1)\n",
    "    y_i = np.array([1 if label == i else 0 for label in y])\n",
    "    y_i = np.reshape(y_i, (m, 1))\n",
    "    fmins.append(minimize(fun=cost, x0=theta, args=(X_with_one_column, y_i.T, learning_rate), method='TNC', jac=gradient))\n",
    "    #all_theta[i-1,:] = fmin.x\n",
    "        \n",
    "    #print y_i.shape, theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for i in range(1, 11):\n",
    "    y_i = np.array([1 if label == i else 0 for label in y])\n",
    "    lr = LogisticRegression()\n",
    "    fit = lr.fit(X, y_i)\n",
    "    clfs.append(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.633404544327858e-09\n",
      "0.0006103940043565629\n",
      "0.00017014038245174673\n",
      "1.8589488407551303e-07\n",
      "0.0015321872635531229\n",
      "4.553540446662352e-05\n",
      "6.476909426029784e-05\n",
      "8.527510169337372e-05\n",
      "0.0020051484952165917\n",
      "0.9966491889741965\n"
     ]
    }
   ],
   "source": [
    "for lr in clfs:\n",
    "    meow = np.matrix(X[0])*lr.coef_.T\n",
    "    lr.coef_.shape, lr.intercept_.shape, np.matrix(X[0]).shape\n",
    "    print sigmoid(np.asscalar(meow) + np.asscalar(lr.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
